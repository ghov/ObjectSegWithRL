{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we generate a new image by cropping it from an older image, then we also need to change the polygon\n",
    "# in order to make it fit the new cropped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from os import listdir\n",
    "from torchvision.transforms import Resize\n",
    "from PIL import Image\n",
    "import skimage.io as io\n",
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_directory = '/media/greghovhannisyan/BackupData1/mscoco/images/train2017/'\n",
    "#write_directory = '/media/greghovhannisyan/BackupData1/mscoco/images/resized_images/train_2017_224_224/'\n",
    "annFile = '/media/greghovhannisyan/BackupData1/mscoco/annotations/instances/instances_train2017.json'\n",
    "bbox_crop_write_dir = '/media/greghovhannisyan/BackupData1/mscoco/images/train2017_crop_bbox/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.41s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118.06, 275.46, 17.19, 57.29]\n",
      "[131.43, 277.37, 127.61, 304.11, 120.93, 318.43, 118.06, 327.02, 121.88, 332.75, 127.61, 329.88, 132.86, 323.68, 132.86, 300.29, 135.25, 275.46, 130.95, 275.46]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "sample_ann_id = 1833954\n",
    "temp_list = list()\n",
    "temp_list.append(sample_ann_id)\n",
    "sample_ann = coco.loadAnns(temp_list)\n",
    "print(sample_ann[0]['bbox'])\n",
    "print(sample_ann[0]['segmentation'][0])\n",
    "\n",
    "xmin = sample_ann[0]['bbox'][0]\n",
    "ymin = sample_ann[0]['bbox'][1]\n",
    "temp_seg = sample_ann[0]['segmentation'][0]\n",
    "\n",
    "new_seg = list()\n",
    "length = len(temp_seg)\n",
    "print(length)\n",
    "\n",
    "for i in range(0,length, 2):\n",
    "    new_seg.append(temp_seg[i]-xmin)\n",
    "    new_seg.append(temp_seg[i+1]-ymin)\n",
    "    \n",
    "#print(temp_list)\n",
    "#print(annIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ann[0]['segmentation'][0] = new_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = io.imread(bbox_crop_write_dir + str(sample_ann_id) + '.jpg')\n",
    "print(I.size)\n",
    "plt.figure(); plt.axis('off')\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = list()\n",
    "t_list.append(sample_ann)\n",
    "print(type(sample_ann[0]['image_id']))\n",
    "\n",
    "print(sample_ann[0]['segmentation'][0])\n",
    "\n",
    "plt.imshow(coco.annToMask(sample_ann[0])[0:60,0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

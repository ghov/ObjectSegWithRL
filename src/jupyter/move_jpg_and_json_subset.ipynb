{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Make a function to move a subset of images in a directory and a subset of polygon data in a json file.\n",
    "#    Move the images to a new directory and make a new json with the subset information and save it in the same parent\n",
    "#     folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a vertex and the function will move all images in that vertex(vertex_count file) and move them to a \n",
    "# new directory. It will also make a new json with the segmentation polygons, just for the ids in that vertex and\n",
    "# save them to a new json file with the same format.\n",
    "def move_img_and_poly_by_vertex_subset(vertex_read_path, vertex_filter_value, image_read_directory,\n",
    "                                       polygon_read_path, image_write_directory, polygon_write_path):\n",
    "    \n",
    "    # Files that are in the polygon json but without the appropriate jpg file\n",
    "    failed_to_move_set = set()\n",
    "    \n",
    "    # Open the vertex json to read the data\n",
    "    with open(vertex_read_path, 'r') as vertex_read:\n",
    "        vertex_json = json.load(vertex_read)\n",
    "        \n",
    "    # Get the id values for the provided vertex\n",
    "    # The ids here are all in integer format\n",
    "    filter_ids = vertex_json[vertex_filter_value]\n",
    "    filter_ids_copy = filter_ids.copy()\n",
    "    \n",
    "    # Open the json with the polygon segemntation information\n",
    "    # The keys (segmentation ids) are all in string format\n",
    "    with open(polygon_read_path, 'r') as poly_read:\n",
    "        polygon_json = json.load(poly_read)\n",
    "    \n",
    "    # Collect the polygons based on the filter_ids\n",
    "    filter_poly_dict = dict()\n",
    "    for val in filter_ids:\n",
    "        try:\n",
    "            filter_poly_dict[str(val)] = polygon_json[str(val)]\n",
    "        except KeyError:\n",
    "            filter_ids_copy.remove(val)\n",
    "        \n",
    "    print(len(filter_poly_dict))\n",
    "    print(len(filter_ids_copy))\n",
    "        \n",
    "    # Move the images based on filter_ids\n",
    "    for val in filter_ids_copy:\n",
    "        # The directory and the segmentation id\n",
    "        image_read_path = image_read_directory + str(val) + '.jpg'\n",
    "        image_write_path = image_write_directory + str(val) + '.jpg'\n",
    "        \n",
    "        # Copy using the shutil copy function. From src to destination.\n",
    "        try:\n",
    "            copy(image_read_path, image_write_path)\n",
    "        except:\n",
    "            del filter_poly_dict[str(val)]\n",
    "            failed_to_move_set.add(val)\n",
    "            \n",
    "    # Save the new polygon json to the write directory\n",
    "    with open(polygon_write_path, 'w') as poly_write:\n",
    "        json.dump(filter_poly_dict, poly_write, indent=4)\n",
    "            \n",
    "    print('Failed to move: ' + str(len(failed_to_move_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_read_path = '/home/greghovhannisyan/PycharmProjects/towards_rlnn_cnn/ObjectSegWithRL/data/vertex_count_segmentation_ids.json'\n",
    "vertex_filter_value = '30'\n",
    "image_read_directory = '/media/greghovhannisyan/BackupData1/mscoco/images/resized_images/train2017_cropped_224_224/'\n",
    "polygon_read_path = '/media/greghovhannisyan/BackupData1/mscoco/annotations/crop_annotations/train2017_crop_bbox_polygons_resized.json'\n",
    "image_write_directory = '/media/greghovhannisyan/BackupData1/mscoco/images/by_vertex/30/'\n",
    "polygon_write_path = '/media/greghovhannisyan/BackupData1/mscoco/annotations/by_vertex/30_vertex_poly_adjusted.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5960\n",
      "5960\n",
      "Failed to move: 0\n"
     ]
    }
   ],
   "source": [
    "move_img_and_poly_by_vertex_subset(vertex_read_path, vertex_filter_value, image_read_directory, polygon_read_path,\n",
    "                                  image_write_directory, polygon_write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'failed_to_move_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9d3eb6f52102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_to_move_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'failed_to_move_set' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
